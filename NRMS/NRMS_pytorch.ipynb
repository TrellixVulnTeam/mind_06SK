{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cs229-mind/mind/blob/main/NRMS/NRMS_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6OlTBsZIlOa"
   },
   "source": [
    "# NRMS: Neural News Recommendation with Multi-Head Self-Attention\n",
    "The following documents are copied from MIND public document.\n",
    "\n",
    "[NRMS](https://wuch15.github.io/paper/EMNLP2019-NRMS.pdf) is a neural news recommendation approach with multi-head selfattention. The core of NRMS is a news encoder and a user encoder. In the newsencoder, a multi-head self-attentions is used to learn news representations from news titles by modeling the interactions between words. In the user encoder, we learn representations of users from their browsed news and use multihead self-attention to capture the relatedness between the news. Besides, we apply additive\n",
    "attention to learn more informative news and user \n",
    "representations by selecting important words and news.\n",
    "\n",
    "## Properties of NRMS:\n",
    "- NRMS is a content-based neural news recommendation approach.\n",
    "- It uses multi-self attention to learn news representations by modeling the iteractions between words and learn user representations by capturing the relationship between user browsed news.\n",
    "- NRMS uses additive attentions to learn informative news and user representations by selecting important words and news.\n",
    "\n",
    "## Data format:\n",
    "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from [MIND small dataset](https://msnews.github.io/). The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
    " \n",
    "**MINDdemo_train** is used for training, and **MINDdemo_dev** is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)\n",
    "\n",
    "### news data\n",
    "This file contains news information including newsid, category, subcatgory, news title, news abstarct, news url and entities in news title, entities in news abstarct.\n",
    "One simple example: <br>\n",
    "\n",
    "`N46466\tlifestyle\tlifestyleroyals\tThe Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\tShop the notebooks, jackets, and more that the royals can't live without.\thttps://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata\t[{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]\t[]`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents information of one piece of news: <br>\n",
    "\n",
    "`[News ID] [Category] [Subcategory] [News Title] [News Abstrct] [News Url] [Entities in News Title] [Entities in News Abstract] ...`\n",
    "\n",
    "<br>\n",
    "\n",
    "We generate a word_dict file to tranform words in news title to word indexes, and a embedding matrix is initted from pretrained glove embeddings.\n",
    "\n",
    "### behaviors data\n",
    "One simple example: <br>\n",
    "`1\tU82271\t11/11/2019 3:28:58 PM\tN3130 N11621 N12917 N4574 N12140 N9748\tN13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents one instance of an impression. The format is like: <br>\n",
    "\n",
    "`[Impression ID] [User ID] [Impression Time] [User Click History] [Impression News]`\n",
    "\n",
    "<br>\n",
    "\n",
    "User Click History is the user historical clicked news before Impression Time. Impression News is the displayed news in an impression, which format is:<br>\n",
    "\n",
    "`[News ID 1]-[label1] ... [News ID n]-[labeln]`\n",
    "\n",
    "<br>\n",
    "Label represents whether the news is clicked by the user. All information of news in User Click History and Impression News can be found in news data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7twSCqkVIlOf"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfNroSyvTlpI",
    "outputId": "4a537a60-bb49-43e0-cba6-45c8c30a373d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.12 (default, Oct 12 2021, 13:49:34) \n",
      "[GCC 7.5.0]\n",
      "Transformers version: 4.12.5\n",
      "Tensorflow version: 2.6.2\n",
      "Pytorch version: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "#define util module path\n",
    "path = '~/mind/NRMS'\n",
    "sys.path.append(path)\n",
    "data_path = '/datadrive/mind/mind'\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "#import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from mind_model.dataloader import DataLoaderTrain, DataLoaderTest, test_iterator, train_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mind_model.preprocess import read_news, read_news_bert, get_doc_input, get_doc_input_bert\n",
    "from mind_model.model_bert import ModelBert\n",
    "from mind_model.parameters import parse_args\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import mind_model.utils as utils\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import logging\n",
    "import datetime\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, get_scheduler, AdamW\n",
    "import torch\n",
    "from torch import nn\n",
    "from mind_model.nrms import TwoTowerModel as TwoTower\n",
    "\n",
    "from mind_model.metrics import roc_auc_score, ndcg_score, mrr_score, ctr_score, cal_metric\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import transformers\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Transformers version: {}\".format(transformers.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Pytorch version: {}\".format(torch.__version__))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmCI4jxzIlOj"
   },
   "source": [
    "## Prepare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        \"\"\"\n",
    "        if you use other metrics where a higher value is better, e.g. accuracy,\n",
    "        call this with its corresponding negative value\n",
    "        \"\"\"\n",
    "        if val_loss < self.best_loss:\n",
    "            early_stop = False\n",
    "            get_better = True\n",
    "            self.counter = 0\n",
    "            self.best_loss = val_loss\n",
    "        else:\n",
    "            get_better = False\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                early_stop = True\n",
    "            else:\n",
    "                early_stop = False\n",
    "\n",
    "        return early_stop, get_better\n",
    "\n",
    "    \n",
    "def run_eval(dev_dataloader, model, run_eval_metric=True, early_stopping=None):\n",
    "    eval_metrics = ['group_auc', 'mean_mrr', 'ndcg@5;10']\n",
    "    group_impr_indexes = []\n",
    "    group_labels = []\n",
    "    group_preds = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    tqdm_util_eval = tqdm(enumerate(dev_dataloader))\n",
    "    early_stop, get_better = False, False\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        for cnt, (impression_ids, user_ids, log_vecs, log_mask, news_vecs, news_bias, labels) in tqdm_util_eval:\n",
    "\n",
    "            #count = cnt\n",
    "            if args.enable_gpu:\n",
    "                #user_ids = user_ids.cuda(non_blocking=True)\n",
    "                log_vecs = log_vecs.cuda(non_blocking=True)\n",
    "                log_mask = log_mask.cuda(non_blocking=True)\n",
    "            user_vecs = model.user_encoder(log_vecs, log_mask).to(torch.device(\"cpu\")).detach().numpy()\n",
    "\n",
    "            for impression_id, user_vec, news_vec, bias, label in zip(\n",
    "                    impression_ids, user_vecs, news_vecs, news_bias, labels):\n",
    "\n",
    "                score = np.dot(\n",
    "                    news_vec, user_vec\n",
    "                )\n",
    "                group_impr_indexes.append(impression_id)\n",
    "                group_labels.append(label)\n",
    "                group_preds.append(score)\n",
    "    if run_eval_metric:\n",
    "        print(\"Print final metrics\")\n",
    "        eval_res = cal_metric(labels=group_labels, preds=group_preds, metrics=eval_metrics)\n",
    "        eval_info = \", \".join(\n",
    "                    [\n",
    "                        str(item[0]) + \":\" + str(item[1])\n",
    "                        for item in sorted(eval_res.items(), key=lambda x: x[0])\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        logging.info(f\"Time taken: {time.time() - start_time :.0f}s\")\n",
    "        print(f\"Eval info: {eval_info} and time taken: {time.time() - start_time:.0f}s\")\n",
    "        if early_stopping is not None:\n",
    "            early_stop, get_better = early_stopping(-eval_res[\"group_auc\"])\n",
    "            \n",
    "    else:\n",
    "        print(f\"Time taken: {time.time() - start_time}s\")\n",
    "    return group_impr_indexes, group_labels, group_preds, (early_stop, get_better)\n",
    "\n",
    "#group_impr_indexes, group_labels, group_preds = run_eval(dev_dataloader, model)\n",
    "\n",
    "def model_fit(model, optimizer, train_dataloader, valid_dir, args, tokenizer, lr_scheduler=None, early_stopping=None):\n",
    "    logging.info('Training...')\n",
    "    LOSS, ACC = [], []\n",
    "\n",
    "    for ep in range(args.epochs):\n",
    "        loss = 0.0\n",
    "        accuracy = 0.0\n",
    "        tqdm_util = tqdm(enumerate(train_dataloader))\n",
    "        model_name = \"bert\"\n",
    "        #series = 0\n",
    "        model_entity = os.path.join(model_path, f\"model_chkpt{datetime.datetime.utcnow().strftime('%Y%m%d')}{model_name}{ep}\")\n",
    "        torch.save(model, model_entity)\n",
    "        for cnt, (user_ids, log_ids, log_mask, input_ids, targets) in tqdm_util:\n",
    "\n",
    "            if cnt > args.max_steps_per_epoch and args.subsampling:\n",
    "                break\n",
    "\n",
    "            if args.enable_gpu:\n",
    "                log_ids = log_ids.cuda(non_blocking=True)\n",
    "                log_mask = log_mask.cuda(non_blocking=True)\n",
    "                input_ids = input_ids.cuda(non_blocking=True)\n",
    "                #user_ids = user_ids.cuda(non_blocking=True)\n",
    "                targets = targets.cuda(non_blocking=True)\n",
    "\n",
    "            bz_loss, y_hat = model(input_ids, log_ids, log_mask, targets)\n",
    "            optimizer.zero_grad()\n",
    "            bz_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "            optimizer.step()\n",
    "            if args.enable_lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            loss += (bz_loss.data.float() - loss) / (cnt + 1)\n",
    "            accuracy += (utils.acc(targets, y_hat) - accuracy) / (cnt + 1)\n",
    "            if loss.isnan() or accuracy.isnan():\n",
    "                break\n",
    "            if cnt % args.log_steps == 0:\n",
    "                #LOSS.append(loss.data)\n",
    "                #ACC.append(accuracy)\n",
    "                #logging.info(\n",
    "                tqdm_util.set_description(\n",
    "                    '[{}] Ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(\n",
    "                        hvd_rank, cnt * args.batch_size, loss.data,\n",
    "                        accuracy))\n",
    "\n",
    "        print('epoch: {} loss: {:.5f} accuracy {:.5f}'.format(ep + 1, loss, accuracy))\n",
    "        \n",
    "        dev_load = test_iterator(model=model, valid_dir=valid_dir, args=args, tokenizer=tokenizer)\n",
    "        dev_dataloader = dev_load[\"iterator\"]            \n",
    "        _, _, _, (early_stop, get_better) = run_eval(dev_dataloader, model, early_stopping)\n",
    "        if get_better:\n",
    "            try:\n",
    "                print(\"Save better model\")\n",
    "                torch.save(\n",
    "                    {\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict':\n",
    "                        optimizer.state_dict(),\n",
    "                        'step':\n",
    "                        step,\n",
    "                        'early_stop_value':\n",
    "                        -val_auc\n",
    "                    }, f\"/datadrive/mind/mind/model_chkpt/{datetime.datetime.utcnow().strftime('%Y%m%d')}ckpt-{cnt * args.batch_size}.pth\")\n",
    "            except OSError as error:\n",
    "                print(f\"OS error: {error}\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.clip_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvGCosniAkhN",
    "outputId": "ce53d27b-c179-43eb-d894-e9842298168e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-26 22:41:35,702] Namespace(batch_size=512, config_name='../Turing/unilm2-base-uncased-config.json', dataset='MIND', do_lower_case=True, drop_rate=0.2, embedding_source='random', enable_gpu=True, enable_hvd=True, epochs=4, f='/home/azureuser/.local/share/jupyter/runtime/kernel-43d66773-55eb-44b1-b8b6-66cb3baba93b.json', filename_pat='behaviors*.tsv', filter_num=0, freeze_embedding=False, load_ckpt_name='epoch-1-40000.pt', log_steps=100, lr=0.0001, max_steps_per_epoch=200000, mode='test', model_dir='./model', model_name_or_path='../Turing/unilm2-base-uncased.bin', model_type='tnlrv3', news_attributes=['title'], news_dim=64, news_query_vector_dim=200, npratio=1, num_attention_heads=20, num_words_abstract=50, num_words_bing=26, num_words_body=50, num_words_title=24, num_words_uet=16, num_workers=2, padded_news_different_word_index=False, pretrain_news_encoder_path='.', process_bing=False, process_uet=False, root_data_dir='~/mind/', save_steps=500, shuffle_buffer_size=10000, test_dir='test', title_share_encoder=False, tokenizer_name='../Turing/unilm2-base-uncased-vocab.txt', train_dir='train', uet_agg_method='attention', use_padded_news_embedding=False, use_pretrain_news_encoder=False, user_log_length=50, user_log_mask=True, user_query_vector_dim=200, word_embedding_dim=768)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe45cbee2174dfea3bb6ca44dabf777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dc6db265ce41779e981972ba7a1978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75397f023482472e9a63dc0c6ff4d03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35ac4654d0046338f605853328ce411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdca2a476483458f968e2236ab4aa125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "utils.setuplogger()\n",
    "args = parse_args()\n",
    "args.enable_hvd = False\n",
    "args.batch_size = 32\n",
    "args.news_dim = 400\n",
    "args.word_emb_size = 768\n",
    "args.user_attributes = None\n",
    "\n",
    "\n",
    "train_dir = os.path.join(data_path, 'MINDsmall_train')\n",
    "train_news_file = os.path.join(train_dir, r'news.tsv')\n",
    "train_behaviors_file = os.path.join(train_dir, r'behaviors.tsv')\n",
    "\n",
    "valid_dir = os.path.join(data_path, 'MINDsmall_dev')\n",
    "valid_news_file = os.path.join(valid_dir, r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(valid_dir, r'behaviors.tsv')\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "config = AutoConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\",config=config)\n",
    "bert_model = bert_model.cuda()\n",
    "\n",
    "finetuneset={\n",
    "'encoder.layer.10.attention.self.query.weight',\n",
    "'encoder.layer.10.attention.self.query.bias',\n",
    "'encoder.layer.10.attention.self.key.weight',\n",
    "'encoder.layer.10.attention.self.key.bias',\n",
    "'encoder.layer.10.attention.self.value.weight',\n",
    "'encoder.layer.10.attention.self.value.bias',\n",
    "'encoder.layer.10.attention.output.dense.weight',\n",
    "'encoder.layer.10.attention.output.dense.bias',\n",
    "'encoder.layer.10.attention.output.LayerNorm.weight',\n",
    "'encoder.layer.10.attention.output.LayerNorm.bias',\n",
    "'encoder.layer.10.intermediate.dense.weight',\n",
    "'encoder.layer.10.intermediate.dense.bias',\n",
    "'encoder.layer.10.output.dense.weight',\n",
    "'encoder.layer.10.output.dense.bias',\n",
    "'encoder.layer.10.output.LayerNorm.weight',\n",
    "'encoder.layer.10.output.LayerNorm.bias',\n",
    "'encoder.layer.11.attention.self.query.weight',\n",
    "'encoder.layer.11.attention.self.query.bias',\n",
    "'encoder.layer.11.attention.self.key.weight',\n",
    "'encoder.layer.11.attention.self.key.bias',\n",
    "'encoder.layer.11.attention.self.value.weight',\n",
    "'encoder.layer.11.attention.self.value.bias',\n",
    "'encoder.layer.11.attention.output.dense.weight',\n",
    "'encoder.layer.11.attention.output.dense.bias',\n",
    "'encoder.layer.11.attention.output.LayerNorm.weight',\n",
    "'encoder.layer.11.attention.output.LayerNorm.bias',\n",
    "'encoder.layer.11.intermediate.dense.weight',\n",
    "'encoder.layer.11.intermediate.dense.bias',\n",
    "'encoder.layer.11.output.dense.weight',\n",
    "'encoder.layer.11.output.dense.bias',\n",
    "'encoder.layer.11.output.LayerNorm.weight',\n",
    "'encoder.layer.11.output.LayerNorm.bias',\n",
    "'pooler.dense.weight',\n",
    "'pooler.dense.bias',\n",
    "'rel_pos_bias.weight',\n",
    "'classifier.weight',\n",
    "'classifier.bias'}\n",
    "for name,param in bert_model.named_parameters():\n",
    "    if name not in finetuneset:\n",
    "        param.requires_grad = False\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4jf58arndKN"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "51282it [00:08, 5795.41it/s]\n",
      "100%|██████████| 51282/51282 [00:00<00:00, 162433.72it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hvd_size, hvd_rank, hvd_local_rank = utils.init_hvd_cuda(\n",
    "    args.enable_hvd, args.enable_gpu)\n",
    "\n",
    "##Load Train data \n",
    "train_load = train_iterator(train_dir=train_dir, args=args, tokenizer=tokenizer)\n",
    "category_dict = train_load[\"category_dict\"]\n",
    "domain_dict = train_load[\"domain_dict\"]\n",
    "subcategory_dict = train_load[\"subcategory_dict\"]\n",
    "train_dataloader = train_load[\"iterator\"]\n",
    "\n",
    "\n",
    "model = TwoTower(args, bert_model, len(category_dict), len(domain_dict), len(subcategory_dict))\n",
    "args.optimizer = 'Adam'\n",
    "args.enable_lr_scheduler = False\n",
    "args.epochs=1\n",
    "args.max_steps_per_epoch = 8000\n",
    "args.subsampling = True\n",
    "\n",
    "if args.enable_gpu:\n",
    "    model = model.cuda()\n",
    "    \n",
    "if args.optimizer == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "elif args.optimizer == 'AdamW':\n",
    "    optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay, correct_bias=args.correct_bias)\n",
    "else:\n",
    "    optimizer = AdamW(model.parameters(), lr=args.lr)\n",
    "    \n",
    "\n",
    "if args.enable_lr_scheduler:\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=args.num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "early_stopping = EarlyStopping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial fit\n",
    "args.epochs=1\n",
    "args.max_steps_per_epoch = 10\n",
    "args.subsampling = True\n",
    "model = model_fit(model=model, optimizer=optimizer, \n",
    "          train_dataloader=train_dataloader, \n",
    "          valid_dir=valid_dir, args=args, \n",
    "          tokenizer=tokenizer, lr_scheduler=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 05:59:35,656] Training...\n",
      "[INFO 2021-11-28 05:59:35,656] DataLoader __iter__()\n",
      "[INFO 2021-11-28 05:59:35,658] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 05:59:35,660] worker_rank:0, worker_size:1, shuffle:True, seed:19, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 05:59:35,660] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.49290, acc: 0.75641: : 5001it [1:12:52,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.49290 accuracy 0.75641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 6039.20it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 157495.59it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 07:12:54,875] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 07:12:54,879] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 07:12:54,879] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 07:12:54,880] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:09, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 07:16:14,523] Time taken: 200s\n",
      "Eval info: group_auc:0.6725, mean_mrr:0.3188, ndcg@10:0.4145, ndcg@5:0.3507 and time taken: 200s\n",
      "[INFO 2021-11-28 07:16:14,524] DataLoader __iter__()\n",
      "[INFO 2021-11-28 07:16:14,526] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 07:16:14,528] worker_rank:0, worker_size:1, shuffle:True, seed:20, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 07:16:14,528] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.48620, acc: 0.76157: : 5001it [1:12:50,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 loss: 0.48620 accuracy 0.76157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 5928.94it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 153903.30it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 08:29:32,013] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 08:29:32,017] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 08:29:32,018] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 08:29:32,018] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:09, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 08:32:52,248] Time taken: 200s\n",
      "Eval info: group_auc:0.6706, mean_mrr:0.3159, ndcg@10:0.4115, ndcg@5:0.3473 and time taken: 200s\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "## Continue fit\n",
    "test_model = torch.load(\"/datadrive/mind/mind/model_chkpt/model_chkpt20211127bert\")\n",
    "optimizer = optim.Adam(test_model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "args.epochs=2\n",
    "args.max_steps_per_epoch = 5000\n",
    "args.subsampling = True\n",
    "test_model = model_fit(model=test_model, optimizer=optimizer, \n",
    "          train_dataloader=train_dataloader, \n",
    "          valid_dir=valid_dir, args=args, \n",
    "          tokenizer=tokenizer, lr_scheduler=None,)\n",
    "# Print optimizer's state_dict\n",
    "print(\"Finished!\")\n",
    "#for var_name in optimizer.state_dict():\n",
    "#    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 08:46:08,207] Training...\n",
      "[INFO 2021-11-28 08:46:08,208] DataLoader __iter__()\n",
      "[INFO 2021-11-28 08:46:08,210] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 08:46:08,213] worker_rank:0, worker_size:1, shuffle:True, seed:22, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 08:46:08,214] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.48059, acc: 0.76430: : 5001it [1:12:55,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.48059 accuracy 0.76430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 5955.83it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 157077.30it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 09:59:29,857] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 09:59:29,861] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 09:59:29,861] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 09:59:29,862] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:09, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 10:02:51,000] Time taken: 201s\n",
      "Eval info: group_auc:0.6697, mean_mrr:0.3168, ndcg@10:0.4122, ndcg@5:0.3478 and time taken: 201s\n",
      "[INFO 2021-11-28 10:02:51,022] DataLoader __iter__()\n",
      "[INFO 2021-11-28 10:02:51,024] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 10:02:51,025] worker_rank:0, worker_size:1, shuffle:True, seed:23, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 10:02:51,026] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.48004, acc: 0.76495: : 5001it [1:12:56,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 loss: 0.48004 accuracy 0.76495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 5821.46it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 151387.63it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 11:16:14,125] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 11:16:14,129] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 11:16:14,130] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 11:16:14,130] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:10, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 11:19:34,904] Time taken: 201s\n",
      "Eval info: group_auc:0.6651, mean_mrr:0.3152, ndcg@10:0.4093, ndcg@5:0.3452 and time taken: 201s\n",
      "[INFO 2021-11-28 11:19:34,965] DataLoader __iter__()\n",
      "[INFO 2021-11-28 11:19:34,967] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 11:19:34,970] worker_rank:0, worker_size:1, shuffle:True, seed:24, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 11:19:34,970] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.47386, acc: 0.76908: : 5001it [1:12:53,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 loss: 0.47386 accuracy 0.76908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 6019.02it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 149055.72it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 12:32:55,381] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 12:32:55,385] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 12:32:55,386] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 12:32:55,386] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:09, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 12:36:15,103] Time taken: 200s\n",
      "Eval info: group_auc:0.6655, mean_mrr:0.3153, ndcg@10:0.4094, ndcg@5:0.3448 and time taken: 200s\n",
      "[INFO 2021-11-28 12:36:15,144] DataLoader __iter__()\n",
      "[INFO 2021-11-28 12:36:15,146] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 12:36:15,148] worker_rank:0, worker_size:1, shuffle:True, seed:25, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 12:36:15,149] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.47025, acc: 0.77193: : 5001it [1:12:54,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 loss: 0.47025 accuracy 0.77193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 5875.50it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 153265.16it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 13:49:36,355] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 13:49:36,358] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 13:49:36,361] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 13:49:36,362] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:10, 17.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 13:52:57,671] Time taken: 201s\n",
      "Eval info: group_auc:0.6674, mean_mrr:0.3163, ndcg@10:0.4109, ndcg@5:0.3467 and time taken: 201s\n",
      "[INFO 2021-11-28 13:52:57,713] DataLoader __iter__()\n",
      "[INFO 2021-11-28 13:52:57,715] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 13:52:57,718] worker_rank:0, worker_size:1, shuffle:True, seed:26, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 13:52:57,724] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.46512, acc: 0.77485: : 5001it [1:12:53,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 loss: 0.46512 accuracy 0.77485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 5836.65it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 155512.70it/s]\n",
      "100%|██████████| 332/332 [00:19<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 15:06:18,259] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 15:06:18,263] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 15:06:18,264] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 15:06:18,264] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:14, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 15:09:44,273] Time taken: 206s\n",
      "Eval info: group_auc:0.6696, mean_mrr:0.3158, ndcg@10:0.411, ndcg@5:0.3467 and time taken: 206s\n",
      "[INFO 2021-11-28 15:09:44,313] DataLoader __iter__()\n",
      "[INFO 2021-11-28 15:09:44,315] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 15:09:44,317] worker_rank:0, worker_size:1, shuffle:True, seed:27, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 15:09:44,318] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.46243, acc: 0.77623: : 5001it [1:12:54,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 loss: 0.46243 accuracy 0.77623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:06, 6069.98it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 154821.95it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 16:23:05,319] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 16:23:05,323] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 16:23:05,324] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 16:23:05,324] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:09, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 16:26:25,405] Time taken: 200s\n",
      "Eval info: group_auc:0.6686, mean_mrr:0.3154, ndcg@10:0.4102, ndcg@5:0.3469 and time taken: 200s\n",
      "[INFO 2021-11-28 16:26:25,447] DataLoader __iter__()\n",
      "[INFO 2021-11-28 16:26:25,449] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 16:26:25,452] worker_rank:0, worker_size:1, shuffle:True, seed:28, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 16:26:25,453] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.45723, acc: 0.77876: : 5001it [1:12:54,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 loss: 0.45723 accuracy 0.77876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 5897.23it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 153737.99it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 17:39:46,187] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 17:39:46,191] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 17:39:46,191] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 17:39:46,192] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:09, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 17:43:05,811] Time taken: 200s\n",
      "Eval info: group_auc:0.6646, mean_mrr:0.3146, ndcg@10:0.4087, ndcg@5:0.3445 and time taken: 200s\n",
      "[INFO 2021-11-28 17:43:05,852] DataLoader __iter__()\n",
      "[INFO 2021-11-28 17:43:05,854] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_train, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n",
      "[INFO 2021-11-28 17:43:05,856] worker_rank:0, worker_size:1, shuffle:True, seed:29, directory:/datadrive/mind/mind/MINDsmall_train, files:['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 17:43:05,857] data_paths: ['/datadrive/mind/mind/MINDsmall_train/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0] Ed: 160000, train_loss: 0.45493, acc: 0.78135: : 5001it [1:12:53,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 loss: 0.45493 accuracy 0.78135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/py38_default/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "42416it [00:07, 5922.37it/s]\n",
      "100%|██████████| 42416/42416 [00:00<00:00, 145226.45it/s]\n",
      "100%|██████████| 332/332 [00:18<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 18:56:26,420] DataLoader __iter__()\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n",
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 18:56:26,427] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 18:56:26,427] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 18:56:26,428] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:09, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 18:59:47,378] Time taken: 201s\n",
      "Eval info: group_auc:0.6674, mean_mrr:0.3162, ndcg@10:0.4104, ndcg@5:0.3468 and time taken: 201s\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping()\n",
    "\n",
    "args.epochs=8\n",
    "args.max_steps_per_epoch = 5000\n",
    "args.subsampling = True\n",
    "test_model = model_fit(model=test_model, optimizer=optimizer, \n",
    "          train_dataloader=train_dataloader, \n",
    "          valid_dir=valid_dir, args=args, \n",
    "          tokenizer=tokenizer, lr_scheduler=None,early_stopping=early_stopping)\n",
    "# Print optimizer's state_dict\n",
    "print(\"Finished!\")\n",
    "#for var_name in optimizer.state_dict():\n",
    "#    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_ahaftzIlOp"
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-28 20:10:01,600] DataLoader __iter__()\n",
      "[INFO 2021-11-28 20:10:01,602] shut down pool.\n",
      "get_files: /datadrive/mind/mind/MINDsmall_dev, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 20:10:01,606] worker_rank:0, worker_size:1, shuffle:False, seed:6, directory:/datadrive/mind/mind/MINDsmall_dev, files:['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n",
      "[INFO 2021-11-28 20:10:01,606] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-28 20:10:01,607] [StreamReader] path_len:1, paths: ['/datadrive/mind/mind/MINDsmall_dev/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2286it [02:08, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print final metrics\n",
      "[INFO 2021-11-28 20:13:20,862] Time taken: 199s\n",
      "Eval info: group_auc:0.6509, mean_mrr:0.3002, ndcg@10:0.393, ndcg@5:0.3271 and time taken: 199s\n"
     ]
    }
   ],
   "source": [
    "_, _, _, res = run_eval(dev_dataloader, model, run_eval_metric=True, early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(data_path, \"model_chkpt\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "model_name = \"bert\"\n",
    "series = \"adam\"\n",
    "model_entity = os.path.join(model_path, f\"model_chkpt{datetime.datetime.utcnow().strftime('%Y%m%d')}{model_name}{series}\")\n",
    "#model.model.save_weights(os.path.join(model_path, \"nrms_ckpt\"))\n",
    "torch.save(model, model_entity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoFwqhD-IlOp"
   },
   "source": [
    "## Output Predcition File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_WKJ_60_ykHb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/rain/anaconda3/envs/datascience/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "72023it [00:11, 6076.04it/s]\n",
      "100%|██████████| 72023/72023 [00:00<00:00, 138716.10it/s]\n",
      "100%|██████████| 563/563 [00:50<00:00, 11.17it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(data_path, 'MINDsmall_test')\n",
    "test_news_file = os.path.join(test_dir, r'news.tsv')\n",
    "test_behaviors_file = os.path.join(test_dir, r'behaviors.tsv')\n",
    "\n",
    "test_load = test_iterator(model=model, valid_dir=test_dir, args=args, tokenizer=tokenizer)\n",
    "test_dataloader = test_load[\"iterator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PWceBziIIlOp",
    "outputId": "77fea63b-5ad6-4428-a010-7aab31d21a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-25 14:09:41,468] DataLoader __iter__()\n",
      "get_files: /home/rain/data/MINDsmall_test, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/home/rain/data/MINDsmall_test/behaviors.tsv']\n",
      "[INFO 2021-11-25 14:09:41,473] worker_rank:0, worker_size:1, shuffle:False, seed:0, directory:/home/rain/data/MINDsmall_test, files:['/home/rain/data/MINDsmall_test/behaviors.tsv']\n",
      "[INFO 2021-11-25 14:09:41,474] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-25 14:09:41,475] [StreamReader] path_len:1, paths: ['/home/rain/data/MINDsmall_test/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:02, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.257753372192383s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#group_impr_indexes, group_labels, group_preds = model.run_fast_eval(test_news_file, test_behaviors_file)\n",
    "\n",
    "group_impr_indexes, group_labels, group_preds = run_eval(test_dataloader, model, run_eval_metric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO 2021-11-25 14:09:43,732] DataLoader __iter__()\n",
      "[INFO 2021-11-25 14:09:43,733] shut down pool.\n",
      "get_files: /home/rain/data/MINDsmall_test, behaviors*.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: ['/home/rain/data/MINDsmall_test/behaviors.tsv']\n",
      "[INFO 2021-11-25 14:09:43,737] worker_rank:0, worker_size:1, shuffle:False, seed:1, directory:/home/rain/data/MINDsmall_test, files:['/home/rain/data/MINDsmall_test/behaviors.tsv']\n",
      "[INFO 2021-11-25 14:09:43,738] visible_devices:[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[INFO 2021-11-25 14:09:43,738] [StreamReader] path_len:1, paths: ['/home/rain/data/MINDsmall_test/behaviors.tsv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:02, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.394899606704712s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "group_impr_indexes1, group_labels1, group_preds1 = run_eval(test_dataloader, test_model, run_eval_metric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vNTTOn7NIlOq",
    "outputId": "05cda72a-97e8-48a3-c85a-021ff1944318"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 33231.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predfile = f'prediction{series}.txt'\n",
    "zip_file = f'prediction{series}.zip'\n",
    "with open(os.path.join(data_path, predfile), 'w') as f:\n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        #impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9_xKcRYyIlOq"
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "f.write(os.path.join(data_path, predfile), arcname='prediction.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWhPpQm6IlOq"
   },
   "source": [
    "## Reference\n",
    "\\[1\\] Wu et al. \"Neural News Recommendation with Multi-Head Self-Attention.\" in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<br>\n",
    "\\[2\\] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\n",
    "\\[3\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzYzsCwmU3lX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [
    "qrEc27EYIlOm"
   ],
   "include_colab_link": true,
   "name": "NRMS_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
